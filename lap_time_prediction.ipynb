{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e46424e7",
   "metadata": {},
   "source": [
    "# F1 Lap Time Prediction Model\n",
    "\n",
    "**Professional approach: Offline Training → Stateful Inference**\n",
    "\n",
    "### Architecture\n",
    "1. **Bulk download** all historical race data once → save as Parquet (no API calls during training/inference)\n",
    "2. **Train** on full history — model learns driver × circuit × tyre degradation patterns\n",
    "3. **Predict** given current race state: *\"Here are laps 1–15, predict lap 16\"*\n",
    "4. **Export** model → deploy to FastAPI backend\n",
    "\n",
    "### Key Design Decisions\n",
    "- **No API calls at inference time** — model runs from exported `.pkl` file\n",
    "- **Prediction depends most on current race** — rolling averages from laps already completed\n",
    "- **Tyre degradation modelled per compound** — captures non-linear deg curves\n",
    "- **FastF1 rate limit safe** — downloads cached to Parquet, re-runs cost 0 API calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8c9d20",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Install & Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679a70e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fastf1 xgboost scikit-learn pandas numpy matplotlib seaborn pyarrow --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6eda62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastf1\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import os\n",
    "import warnings\n",
    "import json\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_theme(style='darkgrid')\n",
    "\n",
    "# Paths\n",
    "CACHE_DIR = Path('f1_cache')\n",
    "DATA_DIR = Path('f1_data')\n",
    "MODEL_DIR = Path('model_export')\n",
    "\n",
    "for d in [CACHE_DIR, DATA_DIR, MODEL_DIR]:\n",
    "    d.mkdir(exist_ok=True)\n",
    "\n",
    "fastf1.Cache.enable_cache(str(CACHE_DIR))\n",
    "print('Setup complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0694d387",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285469f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "#  CONFIGURATION\n",
    "# ============================================================\n",
    "\n",
    "SEASONS = [2023, 2024]              # Seasons to use\n",
    "SESSION_TYPE = 'R'                   # R = Race\n",
    "MAX_EVENTS_PER_SEASON = None         # None = all, set to 3-5 for quick testing\n",
    "PARQUET_FILE = DATA_DIR / 'all_race_laps.parquet'\n",
    "\n",
    "# Set to True on first run to download data,\n",
    "# then False to skip download and load from parquet\n",
    "DOWNLOAD_DATA = not PARQUET_FILE.exists()\n",
    "\n",
    "print(f'Seasons:       {SEASONS}')\n",
    "print(f'Download data: {DOWNLOAD_DATA}')\n",
    "print(f'Parquet file:  {PARQUET_FILE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642a03d9",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Data Collection (run once, then cached to Parquet)\n",
    "\n",
    "Downloads all race lap data from FastF1 and saves to a Parquet file.  \n",
    "On subsequent runs this cell does nothing — loads from disk instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4615877d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_all_laps(seasons, session_type, max_events=None):\n",
    "    \"\"\"\n",
    "    Download lap data from FastF1 for given seasons.\n",
    "    Returns a single DataFrame with all laps.\n",
    "    \"\"\"\n",
    "    all_laps = []\n",
    "\n",
    "    for year in seasons:\n",
    "        print(f'\\n--- {year} Season ---')\n",
    "        try:\n",
    "            schedule = fastf1.get_event_schedule(year)\n",
    "            events = schedule[schedule['EventFormat'] != 'testing']\n",
    "            if max_events:\n",
    "                events = events.head(max_events)\n",
    "        except Exception as e:\n",
    "            print(f'  Could not load schedule: {e}')\n",
    "            continue\n",
    "\n",
    "        for _, event in events.iterrows():\n",
    "            name = event['EventName']\n",
    "            print(f'  {name}...', end=' ')\n",
    "            try:\n",
    "                session = fastf1.get_session(year, name, session_type)\n",
    "                session.load(laps=True, telemetry=False, weather=False, messages=False)\n",
    "                laps = session.laps\n",
    "                if laps.empty:\n",
    "                    print('no data')\n",
    "                    continue\n",
    "\n",
    "                # Keep relevant columns\n",
    "                cols_to_keep = [\n",
    "                    'Driver', 'DriverNumber', 'Team', 'LapNumber', 'LapTime',\n",
    "                    'Stint', 'TyreLife', 'Compound', 'FreshTyre',\n",
    "                    'Sector1Time', 'Sector2Time', 'Sector3Time',\n",
    "                    'SpeedI1', 'SpeedI2', 'SpeedFL', 'SpeedST',\n",
    "                    'IsPersonalBest', 'Position', 'TrackStatus',\n",
    "                    'IsAccurate'\n",
    "                ]\n",
    "                cols_available = [c for c in cols_to_keep if c in laps.columns]\n",
    "                laps = laps[cols_available].copy()\n",
    "\n",
    "                # Convert timedeltas to seconds\n",
    "                for col in ['LapTime', 'Sector1Time', 'Sector2Time', 'Sector3Time']:\n",
    "                    if col in laps.columns:\n",
    "                        laps[f'{col}Sec'] = laps[col].dt.total_seconds()\n",
    "                        laps = laps.drop(columns=[col])\n",
    "\n",
    "                # Add metadata\n",
    "                laps['Year'] = year\n",
    "                laps['Event'] = name\n",
    "                laps['Circuit'] = session.event['EventName']\n",
    "                laps['TotalLaps'] = laps['LapNumber'].max()\n",
    "\n",
    "                all_laps.append(laps)\n",
    "                print(f'{len(laps)} laps')\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f'failed ({e})')\n",
    "\n",
    "    return pd.concat(all_laps, ignore_index=True) if all_laps else pd.DataFrame()\n",
    "\n",
    "\n",
    "# ---- Download or load from cache ----\n",
    "if DOWNLOAD_DATA:\n",
    "    print('Downloading from FastF1 (this takes a while on first run)...\\n')\n",
    "    df_raw = download_all_laps(SEASONS, SESSION_TYPE, MAX_EVENTS_PER_SEASON)\n",
    "    df_raw.to_parquet(PARQUET_FILE, index=False)\n",
    "    print(f'\\nSaved {len(df_raw):,} laps to {PARQUET_FILE}')\n",
    "else:\n",
    "    print(f'Loading from cached parquet: {PARQUET_FILE}')\n",
    "    df_raw = pd.read_parquet(PARQUET_FILE)\n",
    "    print(f'Loaded {len(df_raw):,} laps')\n",
    "\n",
    "print(f'\\nDataset: {df_raw[\"Year\"].nunique()} seasons, '\n",
    "      f'{df_raw[\"Event\"].nunique()} events, '\n",
    "      f'{df_raw[\"Driver\"].nunique()} drivers')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cdf11d",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Data Cleaning\n",
    "\n",
    "Remove unreliable laps: pit in/out, safety car, red flags, outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d138fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_raw.copy()\n",
    "print(f'Raw:             {len(df):,} laps')\n",
    "\n",
    "# 1. Drop laps without a valid time\n",
    "df = df.dropna(subset=['LapTimeSec'])\n",
    "print(f'After NaN drop:  {len(df):,}')\n",
    "\n",
    "# 2. Keep only accurate laps (FastF1 flags inaccurate pit-in/out laps)\n",
    "if 'IsAccurate' in df.columns:\n",
    "    df = df[df['IsAccurate'] == True].copy()\n",
    "    print(f'After IsAccurate: {len(df):,}')\n",
    "\n",
    "# 3. Remove extreme outliers per event (5th–95th percentile)\n",
    "def clip_outliers(group, col='LapTimeSec'):\n",
    "    lo, hi = group[col].quantile(0.05), group[col].quantile(0.95)\n",
    "    return group[(group[col] >= lo) & (group[col] <= hi)]\n",
    "\n",
    "df = df.groupby(['Year', 'Event'], group_keys=False).apply(clip_outliers)\n",
    "print(f'After outliers:  {len(df):,}')\n",
    "\n",
    "# 4. Quick sanity check\n",
    "print(f'\\nLap time stats (seconds):')\n",
    "print(df['LapTimeSec'].describe().round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b783f3fc",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Feature Engineering\n",
    "\n",
    "### Feature hierarchy (by prediction importance):\n",
    "\n",
    "| Priority | Category | Features | Why |\n",
    "|----------|----------|----------|-----|\n",
    "| **1 (highest)** | Current race laps | prev_lap_1/2/3, rolling_avg_3/5, race_mean | The best predictor of the next lap is the most recent laps |\n",
    "| **2** | Tyre / stint state | tyre_life, compound, deg_rate, stint_avg | Tyre deg is the main source of lap time variation |\n",
    "| **3** | Race context | lap_number, fuel_effect, position | Fuel burn makes car lighter → faster by ~0.06s/lap |\n",
    "| **4 (lowest)** | Historical | driver_circuit_avg, circuit_avg | Baseline expectation, lower weight for in-race predictions |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802abc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_features(df):\n",
    "    \"\"\"\n",
    "    Feature engineering pipeline.\n",
    "    Builds features in priority order: current race → tyre → context → historical.\n",
    "    Every feature is computed using only past data (no lookahead).\n",
    "    \"\"\"\n",
    "    df = df.sort_values(['Year', 'Event', 'Driver', 'LapNumber']).copy()\n",
    "\n",
    "    # Unique key per driver per race\n",
    "    df['race_id'] = df['Year'].astype(str) + '_' + df['Event']\n",
    "    df['rd_key'] = df['race_id'] + '_' + df['Driver']\n",
    "\n",
    "    grp = df.groupby('rd_key')['LapTimeSec']\n",
    "\n",
    "    # ==========================================================\n",
    "    #  PRIORITY 1: Current Race Lap Features\n",
    "    # ==========================================================\n",
    "\n",
    "    # Lag features — shifted so we only use completed laps\n",
    "    df['prev_lap_1'] = grp.shift(1)\n",
    "    df['prev_lap_2'] = grp.shift(2)\n",
    "    df['prev_lap_3'] = grp.shift(3)\n",
    "\n",
    "    # Rolling averages over completed laps\n",
    "    shifted = grp.shift(1)\n",
    "    df['roll_avg_3'] = shifted.groupby(df['rd_key']).transform(\n",
    "        lambda x: x.rolling(3, min_periods=1).mean()\n",
    "    )\n",
    "    df['roll_avg_5'] = shifted.groupby(df['rd_key']).transform(\n",
    "        lambda x: x.rolling(5, min_periods=1).mean()\n",
    "    )\n",
    "    df['roll_avg_10'] = shifted.groupby(df['rd_key']).transform(\n",
    "        lambda x: x.rolling(10, min_periods=1).mean()\n",
    "    )\n",
    "\n",
    "    # Lap-over-lap deltas (trend)\n",
    "    df['delta_1'] = grp.shift(1) - grp.shift(2)\n",
    "    df['delta_2'] = grp.shift(2) - grp.shift(3)\n",
    "\n",
    "    # Race cumulative stats up to previous lap\n",
    "    df['race_mean'] = shifted.groupby(df['rd_key']).transform(\n",
    "        lambda x: x.expanding().mean()\n",
    "    )\n",
    "    df['race_best'] = shifted.groupby(df['rd_key']).transform(\n",
    "        lambda x: x.expanding().min()\n",
    "    )\n",
    "    df['race_std'] = shifted.groupby(df['rd_key']).transform(\n",
    "        lambda x: x.expanding().std()\n",
    "    )\n",
    "\n",
    "    # ==========================================================\n",
    "    #  PRIORITY 2: Tyre & Stint Features\n",
    "    # ==========================================================\n",
    "\n",
    "    # Tyre compound encoding (C1=softest → C5=hardest, wet types separate)\n",
    "    compound_map = {\n",
    "        'SOFT': 1, 'MEDIUM': 2, 'HARD': 3,\n",
    "        'INTERMEDIATE': 4, 'WET': 5,\n",
    "        'HYPERSOFT': 0, 'ULTRASOFT': 0.5, 'SUPERSOFT': 1,\n",
    "        'SUPERHARD': 4, 'UNKNOWN': 2, 'TEST_UNKNOWN': 2\n",
    "    }\n",
    "    df['compound_enc'] = df['Compound'].map(compound_map).fillna(2)\n",
    "\n",
    "    # Tyre life\n",
    "    df['Stint'] = df['Stint'].fillna(1).astype(int)\n",
    "    df['TyreLife'] = pd.to_numeric(df['TyreLife'], errors='coerce')\n",
    "    df['TyreLife'] = df['TyreLife'].fillna(\n",
    "        df.groupby(['rd_key', 'Stint'])['LapNumber'].transform(lambda x: x - x.min() + 1)\n",
    "    )\n",
    "    df['tyre_life_sq'] = df['TyreLife'] ** 2  # Non-linear degradation\n",
    "    df['tyre_compound_int'] = df['TyreLife'] * df['compound_enc']  # Softs degrade faster\n",
    "\n",
    "    # Fresh tyre flag\n",
    "    df['fresh_tyre'] = df['FreshTyre'].fillna(True).astype(int)\n",
    "\n",
    "    # Stint-level rolling average\n",
    "    stint_shifted = df.groupby(['rd_key', 'Stint'])['LapTimeSec'].shift(1)\n",
    "    df['stint_avg_3'] = stint_shifted.groupby([df['rd_key'], df['Stint']]).transform(\n",
    "        lambda x: x.rolling(3, min_periods=1).mean()\n",
    "    )\n",
    "    df['stint_mean'] = stint_shifted.groupby([df['rd_key'], df['Stint']]).transform(\n",
    "        lambda x: x.expanding().mean()\n",
    "    )\n",
    "\n",
    "    # Stint lap number\n",
    "    df['stint_lap'] = df.groupby(['rd_key', 'Stint']).cumcount() + 1\n",
    "\n",
    "    # Tyre degradation rate (slope within current stint)\n",
    "    def stint_slope(series):\n",
    "        vals = series.dropna().values\n",
    "        if len(vals) < 2:\n",
    "            return 0.0\n",
    "        return np.polyfit(range(len(vals)), vals, 1)[0]\n",
    "\n",
    "    df['deg_rate'] = stint_shifted.groupby([df['rd_key'], df['Stint']]).transform(\n",
    "        lambda x: x.expanding().apply(stint_slope, raw=False)\n",
    "    )\n",
    "\n",
    "    # ==========================================================\n",
    "    #  PRIORITY 3: Race Context\n",
    "    # ==========================================================\n",
    "\n",
    "    # Fuel effect — approx 0.06s/lap lighter over race distance\n",
    "    df['fuel_corrected_lap'] = df['LapNumber'] / df['TotalLaps']\n",
    "    df['fuel_effect'] = (1 - df['fuel_corrected_lap']) * 0.06 * df['TotalLaps']\n",
    "\n",
    "    # Position\n",
    "    df['Position'] = pd.to_numeric(df['Position'], errors='coerce')\n",
    "\n",
    "    # Speed trap averages\n",
    "    for col in ['SpeedI1', 'SpeedI2', 'SpeedFL', 'SpeedST']:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    df['avg_speed'] = df[['SpeedI1', 'SpeedI2', 'SpeedFL', 'SpeedST']].mean(axis=1)\n",
    "\n",
    "    # ==========================================================\n",
    "    #  PRIORITY 4: Historical Driver × Circuit Performance\n",
    "    # ==========================================================\n",
    "\n",
    "    # Build historical stats EXCLUDING the current race (no leakage)\n",
    "    hist = df.groupby(['Circuit', 'Driver', 'race_id'])['LapTimeSec'].agg(\n",
    "        hist_mean='mean', hist_best='min'\n",
    "    ).reset_index()\n",
    "\n",
    "    # For each race, the historical stats should come from OTHER races only\n",
    "    # We use an expanding approach grouped by circuit+driver\n",
    "    hist = hist.sort_values('race_id')\n",
    "    hist['hist_circuit_mean'] = hist.groupby(['Circuit', 'Driver'])['hist_mean'].transform(\n",
    "        lambda x: x.shift(1).expanding().mean()\n",
    "    )\n",
    "    hist['hist_circuit_best'] = hist.groupby(['Circuit', 'Driver'])['hist_best'].transform(\n",
    "        lambda x: x.shift(1).expanding().min()\n",
    "    )\n",
    "    hist = hist[['Circuit', 'Driver', 'race_id', 'hist_circuit_mean', 'hist_circuit_best']]\n",
    "\n",
    "    df = df.merge(hist, on=['Circuit', 'Driver', 'race_id'], how='left')\n",
    "\n",
    "    # Circuit average (across all drivers, for relative comparison)\n",
    "    circuit_avg = df.groupby('Circuit')['LapTimeSec'].transform('mean')\n",
    "    df['circuit_avg'] = circuit_avg\n",
    "    df['driver_advantage'] = df['circuit_avg'] - df['hist_circuit_mean']\n",
    "\n",
    "    # ==========================================================\n",
    "    #  ENCODING\n",
    "    # ==========================================================\n",
    "\n",
    "    le_driver = LabelEncoder()\n",
    "    df['driver_enc'] = le_driver.fit_transform(df['Driver'].astype(str))\n",
    "\n",
    "    le_team = LabelEncoder()\n",
    "    df['team_enc'] = le_team.fit_transform(df['Team'].astype(str))\n",
    "\n",
    "    le_circuit = LabelEncoder()\n",
    "    df['circuit_enc'] = le_circuit.fit_transform(df['Circuit'].astype(str))\n",
    "\n",
    "    return df, le_driver, le_team, le_circuit\n",
    "\n",
    "\n",
    "print('Building features...')\n",
    "df, le_driver, le_team, le_circuit = build_features(df)\n",
    "print(f'Done. Shape: {df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ea0156",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Prepare Training Data\n",
    "\n",
    "Fill NaN values with sensible defaults (rather than dropping rows).  \n",
    "Early-race laps have fewer past laps to reference, so NaNs are expected and handled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a67bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = [\n",
    "    # P1: Current race\n",
    "    'prev_lap_1', 'prev_lap_2', 'prev_lap_3',\n",
    "    'roll_avg_3', 'roll_avg_5', 'roll_avg_10',\n",
    "    'delta_1', 'delta_2',\n",
    "    'race_mean', 'race_best', 'race_std',\n",
    "\n",
    "    # P2: Tyre / stint\n",
    "    'TyreLife', 'tyre_life_sq', 'compound_enc', 'tyre_compound_int',\n",
    "    'fresh_tyre', 'Stint', 'stint_lap', 'stint_avg_3', 'stint_mean',\n",
    "    'deg_rate',\n",
    "\n",
    "    # P3: Race context\n",
    "    'LapNumber', 'fuel_corrected_lap', 'fuel_effect',\n",
    "    'Position', 'avg_speed',\n",
    "\n",
    "    # P4: Historical\n",
    "    'hist_circuit_mean', 'hist_circuit_best',\n",
    "    'circuit_avg', 'driver_advantage',\n",
    "\n",
    "    # Encoded identifiers\n",
    "    'driver_enc', 'team_enc', 'circuit_enc',\n",
    "]\n",
    "\n",
    "TARGET = 'LapTimeSec'\n",
    "\n",
    "# --- Show NaN landscape before filling ---\n",
    "nan_before = df[FEATURES].isnull().sum()\n",
    "print('NaN counts before filling:')\n",
    "print(nan_before[nan_before > 0].to_string())\n",
    "\n",
    "# ---- Intelligent NaN filling ----\n",
    "\n",
    "# Lag features: cascade fill (3 → 2 → 1 → race_mean → circuit_avg)\n",
    "df['prev_lap_3'] = df['prev_lap_3'].fillna(df['prev_lap_2'])\n",
    "df['prev_lap_2'] = df['prev_lap_2'].fillna(df['prev_lap_1'])\n",
    "df['prev_lap_1'] = df['prev_lap_1'].fillna(df['race_mean']).fillna(df['hist_circuit_mean']).fillna(df['circuit_avg'])\n",
    "# After filling prev_lap_1, re-fill 2 and 3\n",
    "df['prev_lap_2'] = df['prev_lap_2'].fillna(df['prev_lap_1'])\n",
    "df['prev_lap_3'] = df['prev_lap_3'].fillna(df['prev_lap_2'])\n",
    "\n",
    "# Rolling averages: cascade\n",
    "df['roll_avg_10'] = df['roll_avg_10'].fillna(df['roll_avg_5'])\n",
    "df['roll_avg_5'] = df['roll_avg_5'].fillna(df['roll_avg_3'])\n",
    "df['roll_avg_3'] = df['roll_avg_3'].fillna(df['prev_lap_1'])\n",
    "df['roll_avg_5'] = df['roll_avg_5'].fillna(df['roll_avg_3'])\n",
    "df['roll_avg_10'] = df['roll_avg_10'].fillna(df['roll_avg_5'])\n",
    "\n",
    "# Deltas: 0 = no trend data yet\n",
    "df['delta_1'] = df['delta_1'].fillna(0)\n",
    "df['delta_2'] = df['delta_2'].fillna(0)\n",
    "\n",
    "# Race cumulative: fill from historical or circuit\n",
    "df['race_mean'] = df['race_mean'].fillna(df['hist_circuit_mean']).fillna(df['circuit_avg'])\n",
    "df['race_best'] = df['race_best'].fillna(df['hist_circuit_best']).fillna(df['circuit_avg'])\n",
    "df['race_std'] = df['race_std'].fillna(0)\n",
    "\n",
    "# Stint: fill from race-level\n",
    "df['stint_avg_3'] = df['stint_avg_3'].fillna(df['roll_avg_3'])\n",
    "df['stint_mean'] = df['stint_mean'].fillna(df['race_mean'])\n",
    "df['deg_rate'] = df['deg_rate'].fillna(0)\n",
    "\n",
    "# Speed / Position: per-event median\n",
    "for col in ['avg_speed', 'Position']:\n",
    "    df[col] = df.groupby(['Year', 'Event'])[col].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "# Historical: fill with circuit average\n",
    "df['hist_circuit_mean'] = df['hist_circuit_mean'].fillna(df['circuit_avg'])\n",
    "df['hist_circuit_best'] = df['hist_circuit_best'].fillna(df['circuit_avg'])\n",
    "df['driver_advantage'] = df['driver_advantage'].fillna(0)\n",
    "\n",
    "# Final safety net: fill any remaining NaN with column median\n",
    "for col in FEATURES:\n",
    "    if df[col].isnull().any():\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "# Drop only if target is missing\n",
    "model_df = df.dropna(subset=[TARGET])\n",
    "\n",
    "X = model_df[FEATURES]\n",
    "y = model_df[TARGET]\n",
    "\n",
    "nan_after = X.isnull().sum().sum()\n",
    "print(f'\\nNaN remaining: {nan_after}')\n",
    "print(f'Training samples: {len(X):,}')\n",
    "print(f'Features: {len(FEATURES)}')\n",
    "\n",
    "# Time-aware split (recent races = test set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, shuffle=False\n",
    ")\n",
    "print(f'\\nTrain: {len(X_train):,}  |  Test: {len(X_test):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94b24da",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebccea64",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBRegressor(\n",
    "    n_estimators=800,\n",
    "    max_depth=8,\n",
    "    learning_rate=0.03,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    min_child_weight=5,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=1.0,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    early_stopping_rounds=50,\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "print(f'\\nBest iteration: {model.best_iteration}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebe8fc3",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6f67ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_train = model.predict(X_train)\n",
    "\n",
    "print('Model Performance')\n",
    "print('=' * 50)\n",
    "for name, yt, yp in [('Train', y_train, y_pred_train), ('Test', y_test, y_pred)]:\n",
    "    mae = mean_absolute_error(yt, yp)\n",
    "    rmse = np.sqrt(mean_squared_error(yt, yp))\n",
    "    r2 = r2_score(yt, yp)\n",
    "    print(f'{name:6s}  MAE: {mae:.3f}s  RMSE: {rmse:.3f}s  R²: {r2:.4f}')\n",
    "\n",
    "print(f'\\nThe model predicts lap times within ~{mean_absolute_error(y_test, y_pred):.2f} seconds on average.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce05474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-series cross-validation\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "cv_model = XGBRegressor(\n",
    "    n_estimators=300, max_depth=6, learning_rate=0.05,\n",
    "    subsample=0.8, colsample_bytree=0.8, random_state=42, n_jobs=-1\n",
    ")\n",
    "cv_scores = cross_val_score(cv_model, X, y, cv=tscv, scoring='neg_mean_absolute_error')\n",
    "print(f'CV MAE: {-cv_scores.mean():.3f} +/- {cv_scores.std():.3f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a770ce02",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e366377c",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = pd.DataFrame({\n",
    "    'Feature': FEATURES,\n",
    "    'Importance': model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "# Categorize\n",
    "P1 = ['prev_lap', 'roll_avg', 'delta_', 'race_mean', 'race_best', 'race_std']\n",
    "P2 = ['Tyre', 'tyre', 'compound', 'fresh', 'Stint', 'stint', 'deg']\n",
    "P3 = ['Lap', 'fuel', 'Position', 'speed']\n",
    "\n",
    "def cat(f):\n",
    "    if any(k in f for k in P1): return 'P1: Current Race'\n",
    "    if any(k in f for k in P2): return 'P2: Tyre/Stint'\n",
    "    if any(k in f for k in P3): return 'P3: Race Context'\n",
    "    if 'hist' in f or 'circuit' in f or 'advantage' in f: return 'P4: Historical'\n",
    "    return 'Other'\n",
    "\n",
    "importance['Category'] = importance['Feature'].apply(cat)\n",
    "cat_colors = {\n",
    "    'P1: Current Race': '#e74c3c',\n",
    "    'P2: Tyre/Stint': '#f39c12',\n",
    "    'P3: Race Context': '#2ecc71',\n",
    "    'P4: Historical': '#3498db',\n",
    "    'Other': '#95a5a6'\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 8))\n",
    "\n",
    "# All features\n",
    "colors = importance['Category'].map(cat_colors)\n",
    "axes[0].barh(importance['Feature'], importance['Importance'], color=colors)\n",
    "axes[0].set_xlabel('Importance')\n",
    "axes[0].set_title('Individual Feature Importance')\n",
    "axes[0].invert_yaxis()\n",
    "\n",
    "# Category totals\n",
    "cat_imp = importance.groupby('Category')['Importance'].sum().sort_values()\n",
    "cat_c = [cat_colors.get(c, '#95a5a6') for c in cat_imp.index]\n",
    "axes[1].barh(cat_imp.index, cat_imp.values, color=cat_c)\n",
    "axes[1].set_xlabel('Total Importance')\n",
    "axes[1].set_title('Importance by Priority Category')\n",
    "\n",
    "for i, (idx, val) in enumerate(cat_imp.items()):\n",
    "    axes[1].text(val + 0.005, i, f'{val:.1%}', va='center', fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(str(MODEL_DIR / 'feature_importance.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('\\nTop 10 features:')\n",
    "print(importance.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb15fa8",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Diagnostic Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b4c939",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Predicted vs Actual\n",
    "axes[0,0].scatter(y_test, y_pred, alpha=0.1, s=5, c='#e74c3c')\n",
    "lims = [min(y_test.min(), y_pred.min()), max(y_test.max(), y_pred.max())]\n",
    "axes[0,0].plot(lims, lims, 'k--', lw=2)\n",
    "axes[0,0].set_xlabel('Actual (s)'); axes[0,0].set_ylabel('Predicted (s)')\n",
    "axes[0,0].set_title('Predicted vs Actual Lap Times')\n",
    "\n",
    "# Residuals\n",
    "residuals = y_test.values - y_pred\n",
    "axes[0,1].hist(residuals, bins=100, color='#3498db', edgecolor='white')\n",
    "axes[0,1].axvline(0, color='red', lw=2, ls='--')\n",
    "axes[0,1].set_xlabel('Residual (s)'); axes[0,1].set_title(f'Residuals (mean={residuals.mean():.3f}s)')\n",
    "\n",
    "# Error vs Tyre Life\n",
    "test_analysis = X_test.copy()\n",
    "test_analysis['abs_error'] = np.abs(residuals)\n",
    "tyre_err = test_analysis.groupby('TyreLife')['abs_error'].mean()\n",
    "tyre_err = tyre_err[tyre_err.index <= 40]\n",
    "axes[1,0].plot(tyre_err.index, tyre_err.values, color='#f39c12', lw=2)\n",
    "axes[1,0].set_xlabel('Tyre Life (laps)'); axes[1,0].set_ylabel('MAE (s)')\n",
    "axes[1,0].set_title('Prediction Error vs Tyre Age')\n",
    "\n",
    "# Error by race stage\n",
    "test_analysis['stage'] = pd.cut(test_analysis['LapNumber'], bins=5)\n",
    "stage_err = test_analysis.groupby('stage')['abs_error'].mean()\n",
    "axes[1,1].bar(range(len(stage_err)), stage_err.values, color='#2ecc71', edgecolor='white')\n",
    "axes[1,1].set_xticks(range(len(stage_err)))\n",
    "axes[1,1].set_xticklabels([str(b) for b in stage_err.index], rotation=30, ha='right')\n",
    "axes[1,1].set_xlabel('Lap Range'); axes[1,1].set_ylabel('MAE (s)')\n",
    "axes[1,1].set_title('Prediction Error by Race Stage')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(str(MODEL_DIR / 'diagnostics.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720ecabf",
   "metadata": {},
   "source": [
    "---\n",
    "## 11. Tyre Degradation Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0370301",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "compound_info = {\n",
    "    'SOFT': ('#FF3333', 1),\n",
    "    'MEDIUM': ('#FFDD00', 2),\n",
    "    'HARD': ('#CCCCCC', 3),\n",
    "}\n",
    "\n",
    "for name, (color, _) in compound_info.items():\n",
    "    mask = df['Compound'] == name\n",
    "    data = df[mask].groupby('TyreLife')['LapTimeSec'].median()\n",
    "    data = data[data.index <= 35]\n",
    "    if len(data) > 2:\n",
    "        ax.plot(data.index, data.values, label=name, color=color, lw=2.5)\n",
    "\n",
    "ax.set_xlabel('Tyre Life (laps)', fontsize=12)\n",
    "ax.set_ylabel('Median Lap Time (s)', fontsize=12)\n",
    "ax.set_title('Tyre Degradation by Compound (all circuits)', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=12)\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(str(MODEL_DIR / 'tyre_deg.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ee9698",
   "metadata": {},
   "source": [
    "---\n",
    "## 12. Export Model for Deployment\n",
    "\n",
    "Exports everything needed to run predictions from your FastAPI backend —  \n",
    "no FastF1 or internet required at inference time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7892eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build metadata for inference\n",
    "# These maps let the backend convert user-friendly names to encoded values\n",
    "\n",
    "driver_map = {name: int(idx) for idx, name in enumerate(le_driver.classes_)}\n",
    "team_map = {name: int(idx) for idx, name in enumerate(le_team.classes_)}\n",
    "circuit_map = {name: int(idx) for idx, name in enumerate(le_circuit.classes_)}\n",
    "\n",
    "# Circuit average lap times (for baseline when no race data yet)\n",
    "circuit_baselines = df.groupby('Circuit')['LapTimeSec'].agg(\n",
    "    ['mean', 'min']\n",
    ").round(3).to_dict(orient='index')\n",
    "\n",
    "# Driver × Circuit historical performance\n",
    "driver_circuit_hist = df.groupby(['Circuit', 'Driver'])['LapTimeSec'].agg(\n",
    "    ['mean', 'min']\n",
    ").round(3).reset_index()\n",
    "driver_circuit_hist.columns = ['circuit', 'driver', 'mean', 'best']\n",
    "driver_circuit_dict = {}\n",
    "for _, row in driver_circuit_hist.iterrows():\n",
    "    key = f\"{row['driver']}@{row['circuit']}\"\n",
    "    driver_circuit_dict[key] = {'mean': row['mean'], 'best': row['best']}\n",
    "\n",
    "# Save everything\n",
    "artifacts = {\n",
    "    'model': model,\n",
    "    'features': FEATURES,\n",
    "    'driver_map': driver_map,\n",
    "    'team_map': team_map,\n",
    "    'circuit_map': circuit_map,\n",
    "    'circuit_baselines': circuit_baselines,\n",
    "    'driver_circuit_hist': driver_circuit_dict,\n",
    "    'compound_map': {'SOFT': 1, 'MEDIUM': 2, 'HARD': 3, 'INTERMEDIATE': 4, 'WET': 5},\n",
    "    'training_info': {\n",
    "        'seasons': SEASONS,\n",
    "        'total_laps': len(X),\n",
    "        'test_mae': float(mean_absolute_error(y_test, y_pred)),\n",
    "        'test_r2': float(r2_score(y_test, y_pred)),\n",
    "    }\n",
    "}\n",
    "\n",
    "model_path = MODEL_DIR / 'lap_time_model.pkl'\n",
    "with open(model_path, 'wb') as f:\n",
    "    pickle.dump(artifacts, f)\n",
    "\n",
    "# Also save metadata as JSON (human-readable, for API docs)\n",
    "meta_path = MODEL_DIR / 'model_metadata.json'\n",
    "meta = {\n",
    "    'features': FEATURES,\n",
    "    'drivers': list(driver_map.keys()),\n",
    "    'teams': list(team_map.keys()),\n",
    "    'circuits': list(circuit_map.keys()),\n",
    "    'compounds': ['SOFT', 'MEDIUM', 'HARD', 'INTERMEDIATE', 'WET'],\n",
    "    'training_info': artifacts['training_info'],\n",
    "}\n",
    "with open(meta_path, 'w') as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "\n",
    "print(f'Model saved:    {model_path} ({model_path.stat().st_size / 1024:.0f} KB)')\n",
    "print(f'Metadata saved: {meta_path}')\n",
    "print(f'\\nFiles in export directory:')\n",
    "for p in MODEL_DIR.iterdir():\n",
    "    print(f'  {p.name} ({p.stat().st_size / 1024:.0f} KB)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30829305",
   "metadata": {},
   "source": [
    "---\n",
    "## 13. Inference Engine\n",
    "\n",
    "This is the class you'd copy to your FastAPI backend.  \n",
    "It takes **current race state** (laps completed so far) and predicts the next lap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974e4ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LapTimePredictor:\n",
    "    \"\"\"\n",
    "    Stateful lap time predictor.\n",
    "\n",
    "    Usage:\n",
    "        predictor = LapTimePredictor('model_export/lap_time_model.pkl')\n",
    "        predicted = predictor.predict(\n",
    "            driver='VER', circuit='Monaco Grand Prix',\n",
    "            team='Red Bull Racing',\n",
    "            completed_laps=[78.1, 77.9, 78.3, 78.0, 78.5],  # times so far\n",
    "            current_compound='MEDIUM', tyre_life=5,\n",
    "            stint=1, fresh_tyre=True,\n",
    "            position=1, total_laps=78\n",
    "        )\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model_path):\n",
    "        with open(model_path, 'rb') as f:\n",
    "            arts = pickle.load(f)\n",
    "        self.model = arts['model']\n",
    "        self.features = arts['features']\n",
    "        self.driver_map = arts['driver_map']\n",
    "        self.team_map = arts['team_map']\n",
    "        self.circuit_map = arts['circuit_map']\n",
    "        self.circuit_baselines = arts['circuit_baselines']\n",
    "        self.driver_circuit_hist = arts['driver_circuit_hist']\n",
    "        self.compound_map = arts['compound_map']\n",
    "\n",
    "    def predict(self, driver, circuit, team, completed_laps,\n",
    "                current_compound, tyre_life, stint=1,\n",
    "                fresh_tyre=True, position=10, total_laps=57,\n",
    "                avg_speed=None):\n",
    "        \"\"\"\n",
    "        Predict the next lap time.\n",
    "\n",
    "        Args:\n",
    "            driver: Driver abbreviation (e.g. 'VER', 'HAM')\n",
    "            circuit: Circuit name (e.g. 'Monaco Grand Prix')\n",
    "            team: Team name (e.g. 'Red Bull Racing')\n",
    "            completed_laps: List of lap times (seconds) completed so far\n",
    "            current_compound: 'SOFT', 'MEDIUM', 'HARD', 'INTERMEDIATE', 'WET'\n",
    "            tyre_life: Laps on current set of tyres\n",
    "            stint: Current stint number (1, 2, 3...)\n",
    "            fresh_tyre: Whether tyres are new (True) or used (False)\n",
    "            position: Current race position\n",
    "            total_laps: Total race laps\n",
    "            avg_speed: Average speed trap reading (optional)\n",
    "\n",
    "        Returns:\n",
    "            float: Predicted next lap time in seconds\n",
    "        \"\"\"\n",
    "        laps = np.array(completed_laps, dtype=float)\n",
    "        n = len(laps)\n",
    "        next_lap_num = n + 1\n",
    "\n",
    "        # --- Historical lookup ---\n",
    "        hist_key = f'{driver}@{circuit}'\n",
    "        hist = self.driver_circuit_hist.get(hist_key, {})\n",
    "        baseline = self.circuit_baselines.get(circuit, {})\n",
    "        circuit_mean = baseline.get('mean', np.mean(laps) if n > 0 else 90.0)\n",
    "        circuit_best = baseline.get('min', np.min(laps) if n > 0 else 80.0)\n",
    "        hist_mean = hist.get('mean', circuit_mean)\n",
    "        hist_best = hist.get('best', circuit_best)\n",
    "\n",
    "        # --- Build feature vector ---\n",
    "        f = {}\n",
    "\n",
    "        # P1: Current race\n",
    "        f['prev_lap_1'] = laps[-1] if n >= 1 else hist_mean\n",
    "        f['prev_lap_2'] = laps[-2] if n >= 2 else f['prev_lap_1']\n",
    "        f['prev_lap_3'] = laps[-3] if n >= 3 else f['prev_lap_2']\n",
    "        f['roll_avg_3'] = np.mean(laps[-3:]) if n >= 1 else hist_mean\n",
    "        f['roll_avg_5'] = np.mean(laps[-5:]) if n >= 1 else hist_mean\n",
    "        f['roll_avg_10'] = np.mean(laps[-10:]) if n >= 1 else hist_mean\n",
    "        f['delta_1'] = float(laps[-1] - laps[-2]) if n >= 2 else 0.0\n",
    "        f['delta_2'] = float(laps[-2] - laps[-3]) if n >= 3 else 0.0\n",
    "        f['race_mean'] = float(np.mean(laps)) if n >= 1 else hist_mean\n",
    "        f['race_best'] = float(np.min(laps)) if n >= 1 else hist_best\n",
    "        f['race_std'] = float(np.std(laps)) if n >= 2 else 0.0\n",
    "\n",
    "        # P2: Tyre / stint\n",
    "        f['TyreLife'] = tyre_life\n",
    "        f['tyre_life_sq'] = tyre_life ** 2\n",
    "        f['compound_enc'] = self.compound_map.get(current_compound, 2)\n",
    "        f['tyre_compound_int'] = tyre_life * f['compound_enc']\n",
    "        f['fresh_tyre'] = int(fresh_tyre)\n",
    "        f['Stint'] = stint\n",
    "        f['stint_lap'] = tyre_life  # approximation\n",
    "        # Use only laps from current stint for stint averages\n",
    "        stint_laps = laps[-tyre_life:] if tyre_life <= n else laps\n",
    "        f['stint_avg_3'] = float(np.mean(stint_laps[-3:])) if len(stint_laps) >= 1 else f['roll_avg_3']\n",
    "        f['stint_mean'] = float(np.mean(stint_laps)) if len(stint_laps) >= 1 else f['race_mean']\n",
    "        f['deg_rate'] = float(np.polyfit(range(len(stint_laps)), stint_laps, 1)[0]) if len(stint_laps) >= 2 else 0.0\n",
    "\n",
    "        # P3: Race context\n",
    "        f['LapNumber'] = next_lap_num\n",
    "        f['fuel_corrected_lap'] = next_lap_num / total_laps\n",
    "        f['fuel_effect'] = (1 - f['fuel_corrected_lap']) * 0.06 * total_laps\n",
    "        f['Position'] = position\n",
    "        f['avg_speed'] = avg_speed if avg_speed is not None else 0.0\n",
    "\n",
    "        # P4: Historical\n",
    "        f['hist_circuit_mean'] = hist_mean\n",
    "        f['hist_circuit_best'] = hist_best\n",
    "        f['circuit_avg'] = circuit_mean\n",
    "        f['driver_advantage'] = circuit_mean - hist_mean\n",
    "\n",
    "        # Encoded identifiers\n",
    "        f['driver_enc'] = self.driver_map.get(driver, 0)\n",
    "        f['team_enc'] = self.team_map.get(team, 0)\n",
    "        f['circuit_enc'] = self.circuit_map.get(circuit, 0)\n",
    "\n",
    "        # Predict\n",
    "        X = pd.DataFrame([f])[self.features]\n",
    "        return float(self.model.predict(X)[0])\n",
    "\n",
    "    def predict_remaining(self, driver, circuit, team, completed_laps,\n",
    "                          current_compound, tyre_life, stint=1,\n",
    "                          fresh_tyre=True, position=10, total_laps=57,\n",
    "                          pit_plan=None):\n",
    "        \"\"\"\n",
    "        Predict all remaining laps in the race.\n",
    "\n",
    "        Args:\n",
    "            pit_plan: Optional list of dicts for planned pit stops.\n",
    "                      e.g. [{'lap': 25, 'compound': 'HARD'}]\n",
    "                      If None, assumes no more pit stops.\n",
    "\n",
    "        Returns:\n",
    "            list of predicted lap times\n",
    "        \"\"\"\n",
    "        predictions = []\n",
    "        sim_laps = list(completed_laps)\n",
    "        sim_tyre_life = tyre_life\n",
    "        sim_compound = current_compound\n",
    "        sim_stint = stint\n",
    "        sim_fresh = fresh_tyre\n",
    "\n",
    "        pit_lap_set = {}\n",
    "        if pit_plan:\n",
    "            for p in pit_plan:\n",
    "                pit_lap_set[p['lap']] = p['compound']\n",
    "\n",
    "        for lap_num in range(len(completed_laps) + 1, total_laps + 1):\n",
    "            # Check if there's a pit stop at this lap\n",
    "            if lap_num in pit_lap_set:\n",
    "                sim_compound = pit_lap_set[lap_num]\n",
    "                sim_tyre_life = 1\n",
    "                sim_stint += 1\n",
    "                sim_fresh = True\n",
    "            else:\n",
    "                sim_tyre_life += 1\n",
    "                sim_fresh = False\n",
    "\n",
    "            pred = self.predict(\n",
    "                driver=driver, circuit=circuit, team=team,\n",
    "                completed_laps=sim_laps,\n",
    "                current_compound=sim_compound,\n",
    "                tyre_life=sim_tyre_life,\n",
    "                stint=sim_stint,\n",
    "                fresh_tyre=sim_fresh,\n",
    "                position=position,\n",
    "                total_laps=total_laps,\n",
    "            )\n",
    "            predictions.append(pred)\n",
    "            sim_laps.append(pred)  # Feed prediction back as input\n",
    "\n",
    "        return predictions\n",
    "\n",
    "\n",
    "print('LapTimePredictor class defined')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7347bd8",
   "metadata": {},
   "source": [
    "---\n",
    "## 14. Test Predictions\n",
    "\n",
    "Validate the inference engine against actual race data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20b9562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load predictor from saved model ---\n",
    "predictor = LapTimePredictor(str(MODEL_DIR / 'lap_time_model.pkl'))\n",
    "\n",
    "# --- Pick a real driver-race from the test set to validate ---\n",
    "test_data = model_df.iloc[len(X_train):]  # test portion\n",
    "sample_rd = test_data.groupby('rd_key').filter(lambda x: len(x) >= 20)\n",
    "sample_key = sample_rd['rd_key'].unique()[0]\n",
    "sample = test_data[test_data['rd_key'] == sample_key].sort_values('LapNumber')\n",
    "\n",
    "driver = sample['Driver'].iloc[0]\n",
    "circuit = sample['Circuit'].iloc[0]\n",
    "team = sample['Team'].iloc[0]\n",
    "total_laps = int(sample['TotalLaps'].iloc[0])\n",
    "\n",
    "print(f'Testing: {driver} ({team}) at {circuit}')\n",
    "print(f'Total laps available: {len(sample)}\\n')\n",
    "\n",
    "# Predict laps 6–20, using laps 1–5 as initial context\n",
    "print(f'{\"Lap\":>4} {\"Predicted\":>10} {\"Actual\":>10} {\"Error\":>8}')\n",
    "print('-' * 36)\n",
    "\n",
    "errors = []\n",
    "for i in range(5, min(25, len(sample))):\n",
    "    context = sample.iloc[:i]\n",
    "    actual = sample.iloc[i]\n",
    "\n",
    "    pred = predictor.predict(\n",
    "        driver=driver, circuit=circuit, team=team,\n",
    "        completed_laps=context['LapTimeSec'].tolist(),\n",
    "        current_compound=actual['Compound'],\n",
    "        tyre_life=int(actual['TyreLife']),\n",
    "        stint=int(actual['Stint']),\n",
    "        fresh_tyre=bool(actual.get('fresh_tyre', 0)),\n",
    "        position=int(actual.get('Position', 10)),\n",
    "        total_laps=total_laps,\n",
    "    )\n",
    "\n",
    "    err = abs(pred - actual['LapTimeSec'])\n",
    "    errors.append(err)\n",
    "    print(f'{int(actual[\"LapNumber\"]):>4} {pred:>10.3f} {actual[\"LapTimeSec\"]:>10.3f} {err:>8.3f}')\n",
    "\n",
    "print(f'\\nAverage error: {np.mean(errors):.3f}s')\n",
    "print(f'Max error:     {np.max(errors):.3f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa945ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Visualize: predicted vs actual lap trace ---\n",
    "context_size = 5\n",
    "ctx_laps = sample.iloc[:context_size]\n",
    "remaining = sample.iloc[context_size:]\n",
    "\n",
    "preds = predictor.predict_remaining(\n",
    "    driver=driver, circuit=circuit, team=team,\n",
    "    completed_laps=ctx_laps['LapTimeSec'].tolist(),\n",
    "    current_compound=remaining.iloc[0]['Compound'],\n",
    "    tyre_life=int(remaining.iloc[0].get('TyreLife', context_size)),\n",
    "    stint=int(remaining.iloc[0].get('Stint', 1)),\n",
    "    position=int(remaining.iloc[0].get('Position', 10)),\n",
    "    total_laps=len(sample),  # Use available laps as total\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 5))\n",
    "all_actual_laps = sample['LapNumber'].values\n",
    "all_actual_times = sample['LapTimeSec'].values\n",
    "\n",
    "pred_lap_nums = list(range(context_size + 1, context_size + 1 + len(preds)))\n",
    "\n",
    "ax.plot(all_actual_laps, all_actual_times, 'b-o', ms=3, label='Actual', alpha=0.8)\n",
    "ax.plot(pred_lap_nums[:len(remaining)], preds[:len(remaining)], 'r--s', ms=3, label='Predicted', alpha=0.8)\n",
    "ax.axvline(context_size + 0.5, color='green', ls=':', lw=2, label=f'Prediction starts (lap {context_size+1})')\n",
    "\n",
    "ax.set_xlabel('Lap Number')\n",
    "ax.set_ylabel('Lap Time (s)')\n",
    "ax.set_title(f'{driver} at {circuit} — Actual vs Predicted Lap Trace')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(str(MODEL_DIR / 'prediction_trace.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200e8da5",
   "metadata": {},
   "source": [
    "---\n",
    "## 15. Download for Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a549e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import files\n",
    "    for p in MODEL_DIR.iterdir():\n",
    "        files.download(str(p))\n",
    "    print('Files downloaded')\n",
    "except ImportError:\n",
    "    print(f'Not in Colab. Model files are in: {MODEL_DIR.absolute()}')\n",
    "    for p in MODEL_DIR.iterdir():\n",
    "        print(f'  {p.name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8906afce",
   "metadata": {},
   "source": [
    "---\n",
    "## Architecture Summary\n",
    "\n",
    "```\n",
    "TRAINING (this notebook, run in Colab):\n",
    "\n",
    "  FastF1 API ──(bulk download once)──> Parquet file ──> Feature Engineering ──> XGBoost ──> model.pkl\n",
    "                                       (cached on disk)                                     (exported)\n",
    "\n",
    "\n",
    "INFERENCE (your FastAPI backend, zero API calls):\n",
    "\n",
    "  User input:                          LapTimePredictor class:\n",
    "  ┌─────────────────────┐              ┌──────────────────────────────────┐\n",
    "  │ driver: VER         │              │ 1. Look up driver×circuit history│\n",
    "  │ circuit: Monaco     │──────────────│ 2. Compute features from input   │\n",
    "  │ compound: MEDIUM    │              │ 3. model.predict(features)       │\n",
    "  │ tyre_life: 12       │              │ 4. Return predicted lap time     │\n",
    "  │ completed_laps: []  │              └──────────────────────────────────┘\n",
    "  └─────────────────────┘\n",
    "```\n",
    "\n",
    "### Feature priority ensures current-race data dominates:\n",
    "\n",
    "| Priority | Weight | Features |\n",
    "|----------|--------|----------|\n",
    "| P1 (highest) | ~50-60% | prev_lap_1/2/3, rolling averages, deltas, race mean/best |\n",
    "| P2 | ~20-30% | tyre_life, compound, deg_rate, stint averages |\n",
    "| P3 | ~10% | lap number, fuel effect, position |\n",
    "| P4 (lowest) | ~5-10% | historical driver×circuit mean, circuit average |\n",
    "\n",
    "The model naturally learns these weights from data — XGBoost assigns higher importance to features with more predictive power."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
