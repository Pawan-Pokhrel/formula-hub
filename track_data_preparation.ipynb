{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fa4a9dc",
   "metadata": {},
   "source": [
    "# F1 Track Visualization — Data Preparation\n",
    "\n",
    "This notebook extracts track layouts and driver position data from FastF1,\n",
    "then saves them as compact JSON files for the FormulaHub backend to serve.\n",
    "\n",
    "**Run once per set of races you want available.** Output files go into `track_data/`.\n",
    "\n",
    "### Pipeline\n",
    "1. Load race session with telemetry from FastF1\n",
    "2. Extract track outline from fastest lap X/Y coordinates\n",
    "3. Extract driver positions at 1 Hz (1 sample/second)\n",
    "4. Normalize coordinates and save as JSON\n",
    "\n",
    "### Output\n",
    "One JSON file per race: `track_data/{year}_{round}.json`  \n",
    "Each contains: track layout + all driver positions + metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be0d2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fastf1 pyarrow --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4209769",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastf1\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "CACHE_DIR = Path('f1_cache')\n",
    "OUTPUT_DIR = Path('track_data')\n",
    "CACHE_DIR.mkdir(exist_ok=True)\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "fastf1.Cache.enable_cache(str(CACHE_DIR))\n",
    "print('Ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9283602e",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Choose which races to process. Each race takes ~2-5 minutes to download telemetry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9d7037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "#  RACES TO PROCESS\n",
    "#  Format: (year, round_number_or_event_name)\n",
    "#  Telemetry is available for 2018+ seasons\n",
    "# ============================================================\n",
    "\n",
    "RACES = [\n",
    "    (2024, 1),   # Bahrain GP\n",
    "    (2024, 6),   # Monaco GP\n",
    "    (2024, 12),  # British GP (Silverstone)\n",
    "    (2024, 14),  # Belgian GP (Spa)\n",
    "    (2024, 16),  # Italian GP (Monza)\n",
    "]\n",
    "\n",
    "# Position sampling rate (Hz). 1 = one sample per second.\n",
    "# Higher = smoother but larger files. 1-2 is ideal.\n",
    "SAMPLE_RATE = 1\n",
    "\n",
    "# Track outline resolution (number of points)\n",
    "TRACK_POINTS = 500\n",
    "\n",
    "print(f'Will process {len(RACES)} races at {SAMPLE_RATE} Hz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2521f5d",
   "metadata": {},
   "source": [
    "## Team Color Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d03bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEAM_COLORS = {\n",
    "    'Red Bull Racing': '#3671C6',\n",
    "    'Ferrari': '#E80020',\n",
    "    'Mercedes': '#27F4D2',\n",
    "    'McLaren': '#FF8000',\n",
    "    'Aston Martin': '#229971',\n",
    "    'Alpine': '#FF87BC',\n",
    "    'Williams': '#64C4FF',\n",
    "    'RB': '#6692FF',\n",
    "    'AlphaTauri': '#6692FF',\n",
    "    'Kick Sauber': '#52E252',\n",
    "    'Alfa Romeo': '#C92D4B',\n",
    "    'Haas F1 Team': '#B6BABD',\n",
    "}\n",
    "\n",
    "def get_team_color(team_name):\n",
    "    \"\"\"Get team color, trying FastF1 first then fallback map.\"\"\"\n",
    "    # Exact match\n",
    "    if team_name in TEAM_COLORS:\n",
    "        return TEAM_COLORS[team_name]\n",
    "    # Partial match\n",
    "    for key, color in TEAM_COLORS.items():\n",
    "        if key.lower() in team_name.lower() or team_name.lower() in key.lower():\n",
    "            return color\n",
    "    return '#FFFFFF'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a9a09a",
   "metadata": {},
   "source": [
    "## Data Extraction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18337d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_track_layout(session, num_points=500):\n",
    "    \"\"\"\n",
    "    Extract the track outline from the fastest lap's telemetry.\n",
    "    Returns normalized X, Y arrays (0-1 range, aspect ratio preserved).\n",
    "    \"\"\"\n",
    "    fastest = session.laps.pick_fastest()\n",
    "    tel = fastest.get_telemetry()\n",
    "\n",
    "    if tel is None or tel.empty or 'X' not in tel.columns:\n",
    "        raise ValueError('No position data in telemetry')\n",
    "\n",
    "    x = tel['X'].values.astype(float)\n",
    "    y = tel['Y'].values.astype(float)\n",
    "\n",
    "    # Remove NaN\n",
    "    mask = ~(np.isnan(x) | np.isnan(y))\n",
    "    x, y = x[mask], y[mask]\n",
    "\n",
    "    if len(x) == 0:\n",
    "        raise ValueError('All position data is NaN')\n",
    "\n",
    "    # Normalize preserving aspect ratio\n",
    "    x_min, x_max = x.min(), x.max()\n",
    "    y_min, y_max = y.min(), y.max()\n",
    "    x_range = x_max - x_min\n",
    "    y_range = y_max - y_min\n",
    "    scale = max(x_range, y_range)\n",
    "\n",
    "    padding = 0.05\n",
    "    x_norm = (x - x_min) / scale * (1 - 2 * padding) + padding\n",
    "    y_norm = (y - y_min) / scale * (1 - 2 * padding) + padding\n",
    "\n",
    "    # Center the shorter axis\n",
    "    if x_range < y_range:\n",
    "        x_norm += (1 - 2 * padding - x_range / scale * (1 - 2 * padding)) / 2\n",
    "    else:\n",
    "        y_norm += (1 - 2 * padding - y_range / scale * (1 - 2 * padding)) / 2\n",
    "\n",
    "    # Downsample to target number of points\n",
    "    step = max(1, len(x_norm) // num_points)\n",
    "    x_ds = np.round(x_norm[::step], 4).tolist()\n",
    "    y_ds = np.round(y_norm[::step], 4).tolist()\n",
    "\n",
    "    return x_ds, y_ds, {\n",
    "        'x_min': float(x_min), 'x_max': float(x_max),\n",
    "        'y_min': float(y_min), 'y_max': float(y_max),\n",
    "        'scale': float(scale), 'padding': padding,\n",
    "    }\n",
    "\n",
    "\n",
    "def normalize_position(val, val_min, scale, padding):\n",
    "    \"\"\"Normalize a coordinate using the same transform as the track layout.\"\"\"\n",
    "    return (val - val_min) / scale * (1 - 2 * padding) + padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec174875",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_driver_positions(session, norm_params, sample_rate=1):\n",
    "    \"\"\"\n",
    "    Extract every driver's position at a fixed sample rate.\n",
    "\n",
    "    Returns:\n",
    "        drivers_info: dict of driver metadata\n",
    "        positions: dict of {abbr: {x: [...], y: [...]}}\n",
    "        duration_sec: total duration in seconds\n",
    "    \"\"\"\n",
    "    drivers_info = {}\n",
    "    raw_positions = {}  # abbr -> DataFrame with time_sec, x, y\n",
    "\n",
    "    # Determine global race time reference\n",
    "    global_min_time = None\n",
    "\n",
    "    for drv_num in session.drivers:\n",
    "        drv_laps = session.laps.pick_drivers(drv_num)\n",
    "        if drv_laps.empty:\n",
    "            continue\n",
    "\n",
    "        abbr = drv_laps.iloc[0]['Driver']\n",
    "        team = str(drv_laps.iloc[0]['Team'])\n",
    "        full_name = f\"{abbr}\"  # FastF1 doesn't always have full name in laps\n",
    "\n",
    "        # Try to get full name from session results\n",
    "        try:\n",
    "            res = session.results\n",
    "            drv_res = res[res['Abbreviation'] == abbr]\n",
    "            if not drv_res.empty:\n",
    "                full_name = str(drv_res.iloc[0]['FullName'])\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        # Collect position data from all laps\n",
    "        pos_frames = []\n",
    "        for _, lap in drv_laps.iterlaps():\n",
    "            try:\n",
    "                pos = lap.get_pos_data()\n",
    "                if pos is not None and not pos.empty and 'X' in pos.columns:\n",
    "                    pos_frames.append(pos[['Date', 'X', 'Y']].copy())\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "        if not pos_frames:\n",
    "            print(f'    {abbr}: no position data, skipping')\n",
    "            continue\n",
    "\n",
    "        combined = pd.concat(pos_frames).sort_values('Date').drop_duplicates(subset='Date')\n",
    "        combined = combined.dropna(subset=['X', 'Y'])\n",
    "\n",
    "        if combined.empty:\n",
    "            continue\n",
    "\n",
    "        if global_min_time is None:\n",
    "            global_min_time = combined['Date'].min()\n",
    "        else:\n",
    "            global_min_time = min(global_min_time, combined['Date'].min())\n",
    "\n",
    "        drivers_info[abbr] = {\n",
    "            'full_name': full_name,\n",
    "            'number': int(drv_num),\n",
    "            'team': team,\n",
    "            'color': get_team_color(team),\n",
    "        }\n",
    "        raw_positions[abbr] = combined\n",
    "\n",
    "    if global_min_time is None:\n",
    "        raise ValueError('No position data found for any driver')\n",
    "\n",
    "    # Find global max time\n",
    "    global_max_time = max(df['Date'].max() for df in raw_positions.values())\n",
    "    duration_sec = (global_max_time - global_min_time).total_seconds()\n",
    "\n",
    "    # Create uniform time grid\n",
    "    sample_interval = 1.0 / sample_rate\n",
    "    time_grid = np.arange(0, duration_sec, sample_interval)\n",
    "\n",
    "    positions = {}\n",
    "    p = norm_params\n",
    "\n",
    "    for abbr, df in raw_positions.items():\n",
    "        df = df.copy()\n",
    "        df['time_sec'] = (df['Date'] - global_min_time).dt.total_seconds()\n",
    "\n",
    "        # Normalize coords with same transform as track\n",
    "        x_raw = df['X'].values.astype(float)\n",
    "        y_raw = df['Y'].values.astype(float)\n",
    "\n",
    "        x_norm = normalize_position(x_raw, p['x_min'], p['scale'], p['padding'])\n",
    "        y_norm = normalize_position(y_raw, p['y_min'], p['scale'], p['padding'])\n",
    "\n",
    "        # Center offset (same as track)\n",
    "        x_range = p['x_max'] - p['x_min']\n",
    "        y_range = p['y_max'] - p['y_min']\n",
    "        if x_range < y_range:\n",
    "            x_norm += (1 - 2*p['padding'] - x_range/p['scale']*(1 - 2*p['padding'])) / 2\n",
    "        else:\n",
    "            y_norm += (1 - 2*p['padding'] - y_range/p['scale']*(1 - 2*p['padding'])) / 2\n",
    "\n",
    "        time_vals = df['time_sec'].values\n",
    "\n",
    "        # Interpolate to uniform grid\n",
    "        x_interp = np.interp(time_grid, time_vals, x_norm)\n",
    "        y_interp = np.interp(time_grid, time_vals, y_norm)\n",
    "\n",
    "        positions[abbr] = {\n",
    "            'x': np.round(x_interp, 4).tolist(),\n",
    "            'y': np.round(y_interp, 4).tolist(),\n",
    "        }\n",
    "        print(f'    {abbr}: {len(time_grid)} samples')\n",
    "\n",
    "    return drivers_info, positions, float(duration_sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53c7e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_lap_times(session):\n",
    "    \"\"\"\n",
    "    Compute cumulative time at each lap boundary (from the leader).\n",
    "    Returns list of seconds from race start where each lap starts.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Use the race winner's lap times as reference\n",
    "        results = session.results.sort_values('Position')\n",
    "        winner_abbr = results.iloc[0]['Abbreviation']\n",
    "        winner_laps = session.laps.pick_drivers(winner_abbr).sort_values('LapNumber')\n",
    "\n",
    "        lap_starts = [0.0]\n",
    "        cumulative = 0.0\n",
    "        for _, lap in winner_laps.iterrows():\n",
    "            lt = lap['LapTime']\n",
    "            if pd.notna(lt):\n",
    "                cumulative += lt.total_seconds()\n",
    "                lap_starts.append(round(cumulative, 1))\n",
    "\n",
    "        return lap_starts\n",
    "    except Exception as e:\n",
    "        print(f'    Could not extract lap times: {e}')\n",
    "        return [0.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b79d93",
   "metadata": {},
   "source": [
    "## Process Races"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc382dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year, event in RACES:\n",
    "    print(f'\\n{\"=\" * 60}')\n",
    "    print(f'Processing: {year} — Event {event}')\n",
    "    print('=' * 60)\n",
    "\n",
    "    try:\n",
    "        # Load session with telemetry\n",
    "        session = fastf1.get_session(year, event, 'R')\n",
    "        session.load(telemetry=True, weather=False, messages=False)\n",
    "\n",
    "        event_name = session.event['EventName']\n",
    "        round_num = int(session.event['RoundNumber'])\n",
    "        circuit_name = session.event.get('CircuitShortName', session.event.get('Location', event_name))\n",
    "        country = session.event.get('Country', '')\n",
    "        event_date = str(session.event.get('EventDate', ''))[:10]\n",
    "\n",
    "        print(f'  Event: {event_name} (Round {round_num})')\n",
    "        print(f'  Circuit: {circuit_name}, {country}')\n",
    "\n",
    "        # 1. Track layout\n",
    "        print('  Extracting track layout...')\n",
    "        track_x, track_y, norm_params = extract_track_layout(session, TRACK_POINTS)\n",
    "        print(f'    Track: {len(track_x)} points')\n",
    "\n",
    "        # 2. Driver positions\n",
    "        print('  Extracting driver positions...')\n",
    "        drivers_info, positions, duration_sec = extract_driver_positions(\n",
    "            session, norm_params, SAMPLE_RATE\n",
    "        )\n",
    "\n",
    "        # 3. Lap timing\n",
    "        print('  Extracting lap times...')\n",
    "        lap_starts = extract_lap_times(session)\n",
    "        total_laps = len(lap_starts) - 1\n",
    "        print(f'    {total_laps} laps')\n",
    "\n",
    "        # 4. Build output JSON\n",
    "        output = {\n",
    "            'info': {\n",
    "                'year': year,\n",
    "                'round': round_num,\n",
    "                'event': event_name,\n",
    "                'circuit': circuit_name,\n",
    "                'country': country,\n",
    "                'date': event_date,\n",
    "                'total_laps': total_laps,\n",
    "                'duration_sec': round(duration_sec, 1),\n",
    "                'sample_rate': SAMPLE_RATE,\n",
    "            },\n",
    "            'track': {\n",
    "                'x': track_x,\n",
    "                'y': track_y,\n",
    "            },\n",
    "            'drivers': drivers_info,\n",
    "            'lap_starts': lap_starts,\n",
    "            'positions': positions,\n",
    "        }\n",
    "\n",
    "        # 5. Save\n",
    "        filename = f'{year}_{round_num}.json'\n",
    "        filepath = OUTPUT_DIR / filename\n",
    "        with open(filepath, 'w') as f:\n",
    "            json.dump(output, f)\n",
    "\n",
    "        size_mb = filepath.stat().st_size / (1024 * 1024)\n",
    "        print(f'  Saved: {filepath} ({size_mb:.1f} MB)')\n",
    "        print(f'  Drivers: {len(drivers_info)}, Duration: {duration_sec/60:.0f} min')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'  FAILED: {e}')\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "print(f'\\n\\nDone! Files in {OUTPUT_DIR}:')\n",
    "for f in sorted(OUTPUT_DIR.glob('*.json')):\n",
    "    print(f'  {f.name} ({f.stat().st_size / 1024:.0f} KB)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe89427",
   "metadata": {},
   "source": [
    "## Preview Track Layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386c776d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Show all extracted tracks\n",
    "files = sorted(OUTPUT_DIR.glob('*.json'))\n",
    "n = len(files)\n",
    "if n == 0:\n",
    "    print('No track data files found.')\n",
    "else:\n",
    "    cols = min(3, n)\n",
    "    rows = (n + cols - 1) // cols\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(6*cols, 6*rows))\n",
    "    if n == 1:\n",
    "        axes = [axes]\n",
    "    else:\n",
    "        axes = axes.flat\n",
    "\n",
    "    for ax, filepath in zip(axes, files):\n",
    "        with open(filepath) as f:\n",
    "            data = json.load(f)\n",
    "        tx = data['track']['x']\n",
    "        ty = data['track']['y']\n",
    "        ax.plot(tx, ty, color='#333', linewidth=8, solid_capstyle='round')\n",
    "        ax.plot(tx, ty, color='#666', linewidth=6, solid_capstyle='round')\n",
    "        # Start/finish\n",
    "        ax.plot(tx[0], ty[0], 'rs', markersize=10)\n",
    "        ax.set_title(f\"{data['info']['event']}\\n{data['info']['year']}\")\n",
    "        ax.set_aspect('equal')\n",
    "        ax.invert_yaxis()\n",
    "        ax.set_facecolor('#111')\n",
    "        ax.tick_params(colors='#666')\n",
    "\n",
    "    # Hide unused axes\n",
    "    for i in range(n, len(list(axes))):\n",
    "        axes[i].set_visible(False)\n",
    "\n",
    "    fig.patch.set_facecolor('#111')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d142c1b",
   "metadata": {},
   "source": [
    "## Download for Backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ccad8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download all JSON files\n",
    "try:\n",
    "    from google.colab import files\n",
    "    for f in sorted(OUTPUT_DIR.glob('*.json')):\n",
    "        files.download(str(f))\n",
    "    print('Files downloaded — place them in formula-hub-backend/track_data/')\n",
    "except ImportError:\n",
    "    print(f'Not in Colab. Files are at: {OUTPUT_DIR.absolute()}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
